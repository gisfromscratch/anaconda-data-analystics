{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.builtins import next\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import logging\n",
    "\n",
    "import dedupe\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(column):\n",
    "    \"\"\"\n",
    "    Do a little bit of data cleaning with the help of Unidecode and Regex.\n",
    "    Things like casing, extra spaces, quotes and new lines can be ignored.\n",
    "    \"\"\"\n",
    "    # If data is missing, indicate that by setting the value to `None`\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "    \n",
    "    try : # python 2/3 string differences\n",
    "        column = column.decode('utf8')\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    column = unidecode(column)\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    # If data is missing, indicate that by setting the value to `None`\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "\n",
    "def readData(filename, encoding, delimiter, header, keyfield):\n",
    "    \"\"\"\n",
    "    Read in our data from a CSV file and create a dictionary of records, \n",
    "    where the key is a unique record ID and each value is dict\n",
    "    \"\"\"\n",
    "\n",
    "    data_d = {}\n",
    "    with open(filename, encoding=encoding) as f:\n",
    "        reader = csv.DictReader(f, fieldnames=header, delimiter=delimiter)\n",
    "        for row in reader:\n",
    "            clean_row = [(k, preProcess(v)) for (k, v) in row.items()]\n",
    "            row_id = int(row[keyfield])\n",
    "            data_d[row_id] = dict(clean_row)\n",
    "\n",
    "    return data_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1598"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ## Import data\n",
    "filename = r'D:/Geonames/modifications-2018-02-24.txt'\n",
    "header = ['geonameid','name','asciiname','alternatenames','latitude','longitude','feature class','feature code','country code','cc2','admin1 code','admin2 code','admin3 code','admin4 code','population','elevation','dem','timezone','modification date']\n",
    "keyfield = 'geonameid'\n",
    "geonames = readData(filename, 'utf-8', '\\t', header, keyfield)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Training\n",
    "fields = [\n",
    "    { 'field':'name', 'type':'String' },\n",
    "    { 'field':'country code', 'type':'Exact', 'has missing':True }\n",
    "]\n",
    "\n",
    "deduper = dedupe.Dedupe(fields)\n",
    "#deduper.sample(geonames, trainingSize)\n",
    "training = dedupe.trainingDataDedupe(geonames, 'geonameid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
