{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.builtins import next\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import logging\n",
    "\n",
    "import dedupe\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Logging\n",
    "logging.getLogger().setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(column):\n",
    "    \"\"\"\n",
    "    Do a little bit of data cleaning with the help of Unidecode and Regex.\n",
    "    Things like casing, extra spaces, quotes and new lines can be ignored.\n",
    "    \"\"\"\n",
    "    # If data is missing, indicate that by setting the value to `None`\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "    \n",
    "    try : # python 2/3 string differences\n",
    "        column = column.decode('utf8')\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    column = unidecode(column)\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    # If data is missing, indicate that by setting the value to `None`\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "\n",
    "def readData(filename, encoding, delimiter, header, keyfield, maxRecordCount=None):\n",
    "    \"\"\"\n",
    "    Read in our data from a CSV file and create a dictionary of records, \n",
    "    where the key is a unique record ID and each value is dict\n",
    "    If no latitude or longitude exists the record is thrown away.\n",
    "    \"\"\"\n",
    "\n",
    "    data_d = {}\n",
    "    recordCount = 0\n",
    "    with open(filename, encoding=encoding) as f:\n",
    "        reader = csv.DictReader(f, fieldnames=header, delimiter=delimiter, quoting=csv.QUOTE_NONE)\n",
    "        for row in reader:\n",
    "            clean_row = [(k, preProcess(v)) for (k, v) in row.items()]\n",
    "            latitude = None\n",
    "            longitude = None\n",
    "            for (k, v) in clean_row:\n",
    "                if 'latitude' == k:\n",
    "                    latitude = float(v)\n",
    "                if 'longitude' == k:\n",
    "                    longitude = float(v)\n",
    "            if latitude and longitude:\n",
    "                clean_row.append(('geometry', (latitude, longitude)))\n",
    "                row_id = int(row[keyfield])\n",
    "                data_d[row_id] = dict(clean_row)\n",
    "                recordCount += 1\n",
    "                if (maxRecordCount and maxRecordCount == recordCount):\n",
    "                    return data_d\n",
    "\n",
    "    return data_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Import data\n",
    "filename = r'D:/Geonames/cities1000.txt'\n",
    "header = ['geonameid','name','asciiname','alternatenames','latitude','longitude','feature class','feature code','country code','cc2','admin1 code','admin2 code','admin3 code','admin4 code','population','elevation','dem','timezone','modification date']\n",
    "keyfield = 'geonameid'\n",
    "maxRecordCount = None\n",
    "data = readData(filename, 'utf-8', '\\t', header, keyfield, maxRecordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Read settings\n",
    "settingsFile = r'D:/Geonames/train.settings'\n",
    "with open(settingsFile, 'rb') as f:\n",
    "    matcher = dedupe.StaticDedupe(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dedupe.backport:Dedupe does not currently support multiprocessing on Windows\n"
     ]
    }
   ],
   "source": [
    "# ## Find best threshold and do the clustering\n",
    "# ## and write the clusters to a file\n",
    "threshold = matcher.threshold(data)\n",
    "matches = matcher.match(data, threshold)\n",
    "matchFile = r'D:/Geonames/matches.txt'\n",
    "with open(matchFile, 'w', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, lineterminator='\\n')\n",
    "    for (clusterId, cluster) in enumerate(matches):\n",
    "        ids, scored = cluster\n",
    "        writer.writerow([clusterId])\n",
    "        for id in ids:\n",
    "            writer.writerow(data[id].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
