{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from future.builtins import next\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import logging\n",
    "\n",
    "import dedupe\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Logging\n",
    "logging.getLogger().setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(column):\n",
    "    \"\"\"\n",
    "    Do a little bit of data cleaning with the help of Unidecode and Regex.\n",
    "    Things like casing, extra spaces, quotes and new lines can be ignored.\n",
    "    \"\"\"\n",
    "    # If data is missing, indicate that by setting the value to `None`\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "    \n",
    "    try : # python 2/3 string differences\n",
    "        column = column.decode('utf8')\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    column = unidecode(column)\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    # If data is missing, indicate that by setting the value to `None`\n",
    "    if not column:\n",
    "        column = None\n",
    "    return column\n",
    "\n",
    "def readData(filename, encoding, delimiter, header, keyfield, maxRecordCount=None):\n",
    "    \"\"\"\n",
    "    Read in our data from a CSV file and create a dictionary of records, \n",
    "    where the key is a unique record ID and each value is dict\n",
    "    \"\"\"\n",
    "\n",
    "    data_d = {}\n",
    "    recordCount = 0\n",
    "    with open(filename, encoding=encoding) as f:\n",
    "        reader = csv.DictReader(f, fieldnames=header, delimiter=delimiter, quoting=csv.QUOTE_NONE)\n",
    "        for row in reader:\n",
    "            clean_row = [(k, preProcess(v)) for (k, v) in row.items()]\n",
    "            row_id = int(row[keyfield])\n",
    "            data_d[row_id] = dict(clean_row)\n",
    "            recordCount += 1\n",
    "            if (maxRecordCount and maxRecordCount == recordCount):\n",
    "                return data_d\n",
    "\n",
    "    return data_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Import training data\n",
    "filename = r'D:/Geonames/geonames_modifications.tsv'\n",
    "header = ['id', 'geonameid','name','asciiname','alternatenames','latitude','longitude','feature class','feature code','country code','cc2','admin1 code','admin2 code','admin3 code','admin4 code','population','elevation','dem','timezone','modification date']\n",
    "keyfield = 'id'\n",
    "maxRecordCount = None\n",
    "trainingData = readData(filename, 'utf-8', '\\t', header, keyfield, maxRecordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\core.py:86: UserWarning: There may be duplicates in the sample\n",
      "  warnings.warn(\"There may be duplicates in the sample\")\n",
      "C:\\bin\\Anaconda3\\lib\\site-packages\\rlr\\lr.py:39: UserWarning: The line-search routine reaches the maximum number of evaluations.\n",
      "  case_weights, self.alpha))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2b3f496acd6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmatcher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdedupe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDedupe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkPairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeledData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\api.py\u001b[0m in \u001b[0;36mmarkPairs\u001b[1;34m(self, labeled_pairs)\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactive_learner\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflatten_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactive_learner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_checkTrainingPairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\labeler.py\u001b[0m in \u001b[0;36mmark\u001b[1;34m(self, pairs, y)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlearner\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m             \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\labeler.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, pairs, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_uncovered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m             self.current_predicates = self.block_learner.learn(dupes,\n\u001b[1;32m--> 189\u001b[1;33m                                                                recall=1.0)\n\u001b[0m\u001b[0;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_old_dupes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdupes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\training.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, matches, recall)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         dupe_cover = cover(self.blocker, matches,\n\u001b[1;32m---> 25\u001b[1;33m                            self.total_cover, compound_length)\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mcomparison_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomparisons\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdupe_cover\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompound_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\training.py\u001b[0m in \u001b[0;36mcover\u001b[1;34m(blocker, pairs, total_cover, compound_length)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_cover\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompound_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m     \u001b[0mcover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoveredPairs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m     \u001b[0mcover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdominators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcover\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_cover\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[0mcover\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcover\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompound_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\training.py\u001b[0m in \u001b[0;36mcoveredPairs\u001b[1;34m(predicates, pairs)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpredicate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredicates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         coverage = {i for i, (record_1, record_2)\n\u001b[1;32m--> 275\u001b[1;33m                     \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m                     if (set(predicate(record_1)) &\n\u001b[0;32m    277\u001b[0m                         set(predicate(record_2, target=True)))}\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\training.py\u001b[0m in \u001b[0;36m<setcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    275\u001b[0m                     \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m                     if (set(predicate(record_1)) &\n\u001b[1;32m--> 277\u001b[1;33m                         set(predicate(record_2, target=True)))}\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcoverage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mcover\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicate\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoverage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\predicates.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, record, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m                 canopy_members = self.index.search(doc,\n\u001b[1;32m--> 146\u001b[1;33m                                                    self.threshold)\n\u001b[0m\u001b[0;32m    147\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mmember\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcanopy_members\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmember\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\bin\\Anaconda3\\lib\\site-packages\\dedupe\\levenshtein.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, doc, threshold)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mmatching_docs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLevenshtein_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mmatching_docs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_doc_to_id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmatching_docs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ## Training\n",
    "fields = [\n",
    "    { 'field':'name', 'type':'String' },\n",
    "    { 'field':'asciiname', 'type':'String' },\n",
    "    { 'field':'latitude', 'type':'String' },\n",
    "    { 'field':'longitude', 'type':'String' },\n",
    "    { 'field':'country code', 'type':'Exact', 'has missing':True }\n",
    "]\n",
    "commonField = 'geonameid'\n",
    "\n",
    "# Create labeled data\n",
    "labeledData = dedupe.trainingDataDedupe(trainingData, commonField)\n",
    "\n",
    "# Create the matcher\n",
    "matcher = dedupe.Dedupe(fields)\n",
    "matcher.sample(trainingData)\n",
    "matcher.markPairs(labeledData)\n",
    "matcher.train()\n",
    "\n",
    "# When finished, save our training to disk\n",
    "trainingFile = r'D:/Geonames/geonames_modifications_training.json'\n",
    "with open(trainingFile, 'w') as tf:\n",
    "    matcher.writeTraining(tf)\n",
    "    \n",
    "# Save our weights and predicates to disk. If the settings file\n",
    "# exists, we will skip all the training and learning next time we run\n",
    "# this file.\n",
    "settingsFile = r'D:/Geonames/geonames_modifications.settings'\n",
    "with open(settingsFile, 'wb') as sf:\n",
    "    matcher.writeSettings(sf)\n",
    "    \n",
    "matcher.cleanupTraining()\n",
    "del matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Import real data\n",
    "filename = r'D:/Geonames/cities1000.txt'\n",
    "header = ['geonameid','name','asciiname','alternatenames','latitude','longitude','feature class','feature code','country code','cc2','admin1 code','admin2 code','admin3 code','admin4 code','population','elevation','dem','timezone','modification date']\n",
    "keyfield = 'geonameid'\n",
    "geonames = readData(filename, 'utf-8', '\\t', header, keyfield)\n",
    "\n",
    "# Create the matcher from the settings file\n",
    "with open(settingsFile, 'rb') as f:\n",
    "    matcher = dedupe.StaticDedupe(f)\n",
    "    threshold = matcher.threshold(geonames)\n",
    "    matches = matcher.match(geonames, threshold)\n",
    "    print('%s duplicates found.' % len(matches))\n",
    "\n",
    "    del matcher\n",
    "\n",
    "def printMatches(matches):\n",
    "    for (clusterId, cluster) in enumerate(matches):\n",
    "        ids, scored = cluster\n",
    "        print(clusterId)\n",
    "        for id in ids:\n",
    "            print (geonames[id]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
